{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10c01dc-edf1-45ef-a1d2-4be52ed82af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.elastix import excute_cmd, register_elastix, control_points_transformix\n",
    "from utils.filemanager import create_directory_if_not_exists, replace_text_in_file, add_and_delete_rows, delete_added_rows\n",
    "from utils.niftimanager import load_nifti, show_nifti\n",
    "from utils.landmarks import get_landmarks_from_txt, write_landmarks_to_list\n",
    "from utils.logger import pprint_objects\n",
    "from utils.metrics import compute_TRE\n",
    "from utils.utils import format_elapsed_time\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "909cbb4f-9c0f-4cb4-af92-77d0404f7949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastix version: 4.700\n",
      "\n",
      "elastix registers a moving image to a fixed image.\n",
      "The registration-process is specified in the parameter file.\n",
      "  --help, -h displays this message and exit\n",
      "  --version  output version information and exit\n",
      "\n",
      "Call elastix from the command line with mandatory arguments:\n",
      "  -f        fixed image\n",
      "  -m        moving image\n",
      "  -out      output directory\n",
      "  -p        parameter file, elastix handles 1 or more \"-p\"\n",
      "\n",
      "Optional extra commands:\n",
      "  -fMask    mask for fixed image\n",
      "  -mMask    mask for moving image\n",
      "  -t0       parameter file for initial transform\n",
      "  -priority set the process priority to high, abovenormal, normal (default),\n",
      "            belownormal, or idle (Windows only option)\n",
      "  -threads  set the maximum number of threads of elastix\n",
      "\n",
      "The parameter-file must contain all the information necessary for elastix to runproperly. That includes which metric to use, which optimizer, which transform, etc. It must also contain information specific for the metric, optimizer, transform, etc. For a usable parameter-file, see the website.\n",
      "\n",
      "Need further help?\n",
      "Check the website http://elastix.isi.uu.nl, or mail elastix@bigr.nl.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(excute_cmd('elastix --help'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6de91c5-99a1-44a4-835b-003484259d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['copd1', 'copd2', 'copd3', 'copd4']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../niftiData/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a91904-951a-4d33-b1a5-bd67d4882574",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../niftiData'\n",
    "\n",
    "# prepare the paths\n",
    "exhale_volumes = [path.replace('\\\\', '/') for path in sorted(glob(os.path.join(train_path, \"***\" , \"*eBHCT.nii.gz\"), recursive=True))]\n",
    "inhale_volumes = [path.replace('\\\\', '/') for path in sorted(glob(os.path.join(train_path, \"***\" , \"*iBHCT.nii.gz\"), recursive=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22fdc2b-985f-43b7-8156-2634f5a72a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../niftiData/copd1/copd1_eBHCT.nii.gz',\n",
       " '../niftiData/copd2/copd2_eBHCT.nii.gz',\n",
       " '../niftiData/copd3/copd3_eBHCT.nii.gz',\n",
       " '../niftiData/copd4/copd4_eBHCT.nii.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exhale_volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8623a82-89cf-46f3-a725-ba597d1af7f3",
   "metadata": {},
   "source": [
    "Register and transform all control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5db59a9-e5cf-42a9-a050-3f7baa2125aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Par0003', 'Par0004', 'Par0007', 'Par0011', 'Par0049']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../elastix-parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9a44a-9744-4cf0-baa3-c0c6dc61cb85",
   "metadata": {},
   "source": [
    "As we have alot of parameters that are suitable for CT registration. We can experiment them and see which performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ed2e8-ad26-41b2-9e8f-aef59821bc9a",
   "metadata": {},
   "source": [
    "Experimenting Par0003 models with elastix and transformix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d4c336-376a-4023-9037-d26f1be5ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../elastix-parameters/Par0049'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Par_base = '../elastix-parameters/Par0049'\n",
    "Par_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae60b2a-bf6e-4fca-b406-ea346a438f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Par0049_stdT-advanced.txt',\n",
       " 'Par0049_stdT2000itr.txt',\n",
       " 'Par0049_stdTL-advanced.txt',\n",
       " 'Par0049_stdTL.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(Par_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa430a-03a1-4188-830f-b9a28ba2b9b8",
   "metadata": {},
   "source": [
    "##### Parameter Model Par0049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2cafe5c-bf6c-4172-9d92-d0b887343a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting using -p \"../elastix-parameters/Par0049/Par0049_stdT2000itr.txt\" params command...\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'name': 'copd1', 'image_dim': [512, 512, 121], 'voxel_dim': [0.625, 0.625, 2.5], 'features': 773, 'displacement_mean': 25.9, 'displacement_std': 11.57, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 1 minutes and 19 seconds\n",
      "Dataset Results:-  (Mean TRE: 26.33) (STD TRE: 11.42).\n",
      "Transformed Results:-  (Mean TRE: 36.51) (STD TRE: 15.82). \n",
      "\n",
      "{'name': 'copd2', 'image_dim': [512, 512, 102], 'voxel_dim': [0.645, 0.645, 2.5], 'features': 612, 'displacement_mean': 21.77, 'displacement_std': 6.46, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 1 minutes and 14 seconds\n",
      "Dataset Results:-  (Mean TRE: 21.79) (STD TRE: 6.46).\n",
      "Transformed Results:-  (Mean TRE: 30.41) (STD TRE: 9.07). \n",
      "\n",
      "{'name': 'copd3', 'image_dim': [512, 512, 126], 'voxel_dim': [0.652, 0.652, 2.5], 'features': 1172, 'displacement_mean': 12.29, 'displacement_std': 6.39, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 1 minutes and 23 seconds\n",
      "Dataset Results:-  (Mean TRE: 12.64) (STD TRE: 6.38).\n",
      "Transformed Results:-  (Mean TRE: 19.18) (STD TRE: 9.05). \n",
      "\n",
      "{'name': 'copd4', 'image_dim': [512, 512, 126], 'voxel_dim': [0.59, 0.59, 2.5], 'features': 786, 'displacement_mean': 30.9, 'displacement_std': 13.49, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 1 minutes and 19 seconds\n",
      "Dataset Results:-  (Mean TRE: 29.58) (STD TRE: 12.92).\n",
      "Transformed Results:-  (Mean TRE: 36.16) (STD TRE: 16.2). \n",
      "\n",
      "Time for overall registrations: 5 minutes and 16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Setting the experiment registration parameter\n",
    "reg_params = f'-p \"{os.path.join(Par_base, \"Par0049_stdT2000itr.txt\")}\"'.replace('\\\\', '/')\n",
    "reg_params_key = 'Par0049_stdT2000itr'\n",
    "\n",
    "print(f\"Experimenting using {reg_params} params command...\")\n",
    "print( \"-----------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for e_path, i_path in zip(exhale_volumes, inhale_volumes):\n",
    "    loop_start_time = time.time()\n",
    "\n",
    "    # get file name\n",
    "    e_filename_full = e_path.split('/')[-1].split('.')[0] #copd1_eBHCT, ..\n",
    "    i_filename_full = i_path.split('/')[-1].split('.')[0] #copd1_iBHCT, ..\n",
    "\n",
    "    sample_name = i_path.split('/')[-1].split('_')[0] #copd1, copd2, ...\n",
    "\n",
    "    # load the dataset dictionary\n",
    "    with open('../rawData/description.json', 'r') as json_file:\n",
    "        dictionary = json.loads(json_file.read())\n",
    "    file_information = dictionary['train'][sample_name]\n",
    "    print(file_information)\n",
    "\n",
    "    # get control points path from rawData dir\n",
    "    e_cntl_pt = f'../rawData/{sample_name}/{sample_name}_300_eBH_xyz_r1.txt'\n",
    "    i_cntl_pt = f'../rawData/{sample_name}/{sample_name}_300_iBH_xyz_r1.txt'\n",
    "\n",
    "    # elastix registration\n",
    "    register_elastix(\n",
    "        fixed_path = i_path, \n",
    "        moving_path = e_path, \n",
    "        # fMask = test_mask,\n",
    "        reg_params = reg_params,\n",
    "        reg_params_key = reg_params_key,\n",
    "        create_dir_callback = create_directory_if_not_exists,\n",
    "        excute_cmd_callback = excute_cmd)\n",
    "\n",
    "    # prepare the points file to match transformix description in the manual\n",
    "    # <index, point>\n",
    "    # <number of points>\n",
    "    # point1 x point1 y [point1 z]\n",
    "    add_and_delete_rows(e_cntl_pt, row1 = '', row2 = ' 300.000000') # row2: number of points (rows)\n",
    "\n",
    "    # transformix control point transformation\n",
    "    output_path = control_points_transformix(\n",
    "        fixed_path = i_path, \n",
    "        moving_path = e_path,\n",
    "        reg_params_key = reg_params_key,\n",
    "        input_points = e_cntl_pt,\n",
    "        transform_path = f'output/{reg_params_key}/images/output_{i_filename_full}/{e_filename_full}/TransformParameters.0.txt',\n",
    "        replace_text_in_file_callback = replace_text_in_file,\n",
    "        create_dir_callback = create_directory_if_not_exists, \n",
    "        excute_cmd_callback = excute_cmd)\n",
    "\n",
    "    loop_end_time = time.time()\n",
    "    loop_elapsed_minutes, loop_elapsed_seconds = format_elapsed_time(loop_start_time, loop_end_time)\n",
    "    print(f\"Time for current registration loop: {loop_elapsed_minutes} minutes and {loop_elapsed_seconds} seconds\")\n",
    "\n",
    "    # get the transformed landmarks\n",
    "    landmarks_path = os.path.join(output_path, 'outputpoints.txt')\n",
    "    transformed_landmarks = get_landmarks_from_txt(landmarks_path, search_key='OutputIndexFixed')\n",
    "\n",
    "    # remove the first two rows that were added for transformix in the moving txt file\n",
    "    delete_added_rows(e_cntl_pt)\n",
    "\n",
    "    # write the landmarks into the output directory of the points\n",
    "    output_landmarks_path = os.path.join(output_path, 'outputpoints_transformed.txt')\n",
    "    write_landmarks_to_list(transformed_landmarks, output_landmarks_path)\n",
    "\n",
    "    # evaluate\n",
    "    TRE_mean, TRE_std = compute_TRE(i_cntl_pt, e_cntl_pt, file_information['voxel_dim'])\n",
    "    print(\"Dataset Results:- \", f\"(Mean TRE: {TRE_mean})\", f\"(STD TRE: {TRE_std}).\")\n",
    "    \n",
    "    TRE_mean, TRE_std = compute_TRE(i_cntl_pt, output_landmarks_path, file_information['voxel_dim'])\n",
    "    print(\"Transformed Results:- \", f\"(Mean TRE: {TRE_mean})\", f\"(STD TRE: {TRE_std}). \\n\")\n",
    "    \n",
    "overall_end_time = time.time()\n",
    "overall_elapsed_minutes, overall_elapsed_seconds = format_elapsed_time(overall_start_time, overall_end_time)\n",
    "print(f\"Time for overall registrations: {overall_elapsed_minutes} minutes and {overall_elapsed_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950fb065-de6a-42d9-ab6d-e4aca5cbc360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting using -p \"../elastix-parameters/Par0049/Par0049_stdT-advanced.txt\" params command...\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'name': 'copd1', 'image_dim': [512, 512, 121], 'voxel_dim': [0.625, 0.625, 2.5], 'features': 773, 'displacement_mean': 25.9, 'displacement_std': 11.57, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 9 minutes and 24 seconds\n",
      "Dataset Results:-  (Mean TRE: 26.33) (STD TRE: 11.42).\n",
      "Transformed Results:-  (Mean TRE: 42.06) (STD TRE: 21.42). \n",
      "\n",
      "{'name': 'copd2', 'image_dim': [512, 512, 102], 'voxel_dim': [0.645, 0.645, 2.5], 'features': 612, 'displacement_mean': 21.77, 'displacement_std': 6.46, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 7 minutes and 40 seconds\n",
      "Dataset Results:-  (Mean TRE: 21.79) (STD TRE: 6.46).\n",
      "Transformed Results:-  (Mean TRE: 34.65) (STD TRE: 10.94). \n",
      "\n",
      "{'name': 'copd3', 'image_dim': [512, 512, 126], 'voxel_dim': [0.652, 0.652, 2.5], 'features': 1172, 'displacement_mean': 12.29, 'displacement_std': 6.39, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 10 minutes and 37 seconds\n",
      "Dataset Results:-  (Mean TRE: 12.64) (STD TRE: 6.38).\n",
      "Transformed Results:-  (Mean TRE: 20.31) (STD TRE: 11.91). \n",
      "\n",
      "{'name': 'copd4', 'image_dim': [512, 512, 126], 'voxel_dim': [0.59, 0.59, 2.5], 'features': 786, 'displacement_mean': 30.9, 'displacement_std': 13.49, 'origin': [1, 1, 1]}\n",
      "Time for current registration loop: 9 minutes and 18 seconds\n",
      "Dataset Results:-  (Mean TRE: 29.58) (STD TRE: 12.92).\n",
      "Transformed Results:-  (Mean TRE: 45.45) (STD TRE: 23.03). \n",
      "\n",
      "Time for overall registrations: 37 minutes and 1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Setting the experiment registration parameter\n",
    "reg_params = f'-p \"{os.path.join(Par_base, \"Par0049_stdT-advanced.txt\")}\"'.replace('\\\\', '/')\n",
    "reg_params_key = 'Par0049_stdT-advanced'\n",
    "\n",
    "print(f\"Experimenting using {reg_params} params command...\")\n",
    "print( \"-----------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for e_path, i_path in zip(exhale_volumes, inhale_volumes):\n",
    "    loop_start_time = time.time()\n",
    "\n",
    "    # get file name\n",
    "    e_filename_full = e_path.split('/')[-1].split('.')[0] #copd1_eBHCT, ..\n",
    "    i_filename_full = i_path.split('/')[-1].split('.')[0] #copd1_iBHCT, ..\n",
    "\n",
    "    sample_name = i_path.split('/')[-1].split('_')[0] #copd1, copd2, ...\n",
    "\n",
    "    # load the dataset dictionary\n",
    "    with open('../rawData/description.json', 'r') as json_file:\n",
    "        dictionary = json.loads(json_file.read())\n",
    "    file_information = dictionary['train'][sample_name]\n",
    "    print(file_information)\n",
    "\n",
    "    # get control points path from rawData dir\n",
    "    e_cntl_pt = f'../rawData/{sample_name}/{sample_name}_300_eBH_xyz_r1.txt'\n",
    "    i_cntl_pt = f'../rawData/{sample_name}/{sample_name}_300_iBH_xyz_r1.txt'\n",
    "\n",
    "    # elastix registration\n",
    "    register_elastix(\n",
    "        fixed_path = i_path, \n",
    "        moving_path = e_path, \n",
    "        # fMask = test_mask,\n",
    "        reg_params = reg_params,\n",
    "        reg_params_key = reg_params_key,\n",
    "        create_dir_callback = create_directory_if_not_exists,\n",
    "        excute_cmd_callback = excute_cmd)\n",
    "    \n",
    "    # prepare the points file to match transformix description in the manual\n",
    "    # <index, point>\n",
    "    # <number of points>\n",
    "    # point1 x point1 y [point1 z]\n",
    "    add_and_delete_rows(e_cntl_pt, row1 = '', row2 = ' 300.000000') # row2: number of points (rows)\n",
    "\n",
    "    # transformix control point transformation\n",
    "    output_path = control_points_transformix(\n",
    "        fixed_path = i_path, \n",
    "        moving_path = e_path,\n",
    "        reg_params_key = reg_params_key,\n",
    "        input_points = e_cntl_pt,\n",
    "        transform_path = f'output/{reg_params_key}/images/output_{i_filename_full}/{e_filename_full}/TransformParameters.0.txt',\n",
    "        replace_text_in_file_callback = replace_text_in_file,\n",
    "        create_dir_callback = create_directory_if_not_exists, \n",
    "        excute_cmd_callback = excute_cmd)\n",
    "\n",
    "    loop_end_time = time.time()\n",
    "    loop_elapsed_minutes, loop_elapsed_seconds = format_elapsed_time(loop_start_time, loop_end_time)\n",
    "    print(f\"Time for current registration loop: {loop_elapsed_minutes} minutes and {loop_elapsed_seconds} seconds\")\n",
    "\n",
    "    # get the transformed landmarks\n",
    "    landmarks_path = os.path.join(output_path, 'outputpoints.txt')\n",
    "    transformed_landmarks = get_landmarks_from_txt(landmarks_path, search_key='OutputIndexFixed')\n",
    "\n",
    "    # remove the first two rows that were added for transformix in the moving txt file\n",
    "    delete_added_rows(e_cntl_pt)\n",
    "\n",
    "    # write the landmarks into the output directory of the points\n",
    "    output_landmarks_path = os.path.join(output_path, 'outputpoints_transformed.txt')\n",
    "    write_landmarks_to_list(transformed_landmarks, output_landmarks_path)\n",
    "\n",
    "    # evaluate\n",
    "    TRE_mean, TRE_std = compute_TRE(i_cntl_pt, e_cntl_pt, file_information['voxel_dim'])\n",
    "    print(\"Dataset Results:- \", f\"(Mean TRE: {TRE_mean})\", f\"(STD TRE: {TRE_std}).\")\n",
    "    \n",
    "    TRE_mean, TRE_std = compute_TRE(i_cntl_pt, output_landmarks_path, file_information['voxel_dim'])\n",
    "    print(\"Transformed Results:- \", f\"(Mean TRE: {TRE_mean})\", f\"(STD TRE: {TRE_std}). \\n\")\\\n",
    "\n",
    "overall_end_time = time.time()\n",
    "overall_elapsed_minutes, overall_elapsed_seconds = format_elapsed_time(overall_start_time, overall_end_time)\n",
    "print(f\"Time for overall registrations: {overall_elapsed_minutes} minutes and {overall_elapsed_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde85e5-35b7-42a8-b798-c7b2d41beb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960f149-a30f-454f-8471-05aa85c0d704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19352e17-f2cd-498c-a03a-4c7390f0c465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c8a51-f6d1-4812-b4e5-de818c3a047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fdfde-1cc2-4c66-9a7d-fa79ef509dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f56fe-ed03-4632-ae70-d340f2b9105e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505f299-ff5c-49f3-ab1f-ecf469a7b8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdf939-2786-480f-8482-35603e980b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
